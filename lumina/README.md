# ðŸŒŸ Lumina - The Local-First Multimodal Code Companion

> A privacy-first AI teaching assistant that helps beginner developers learn programming through visual code representation, empathetic interaction, and adaptive Socratic pedagogy.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.3-blue)](https://www.typescriptlang.org/)
[![React](https://img.shields.io/badge/React-18-61dafb)](https://reactjs.org/)

## ðŸŽ¯ The Problem

Beginner developers face a critical learning barrier:
- **60% of coding time** spent decoding cryptic error messages
- **40% of bootcamp students** stuck for 2+ hours on syntax errors weekly  
- **23% dropout rate** within 3 months, citing frustration and confusion

**Existing tools fail beginners:**
- GitHub Copilot: Autocompletes but doesn't teach
- ChatGPT: Generic responses, no emotional awareness, privacy concerns
- ESLint/Debuggers: Fixed error templates, no pedagogical strategy

## ðŸ’¡ The Solution

Lumina combines three innovations:

1. **Visual Runtime Engine**: Transforms code into interactive Mermaid diagrams (functions, variables, control flow)
2. **Emotion-Aware Pedagogy**: Detects frustration and adapts teaching approach in real-time
3. **Local LLM**: Runs Llama-3-8B on your machine for privacy and zero-latency responses

## âœ¨ Features

### MVP (Hackathon Ready)
- âœ… JavaScript code parsing and visualization
- âœ… Real-time Mermaid diagram generation
- âœ… Sentiment analysis with frustration detection
- âœ… 3-tier Socratic pedagogy (calm â†’ frustrated â†’ direct)
- âœ… Local LLM integration (Ollama + Llama-3-8B)
- âœ… Privacy-first: All processing on-device

### Post-MVP
- ðŸ”„ Python support
- ðŸ”„ Voice interface (Web Speech API)
- ðŸ”„ Session persistence
- ðŸ”„ Interactive code examples library
- ðŸ”„ Performance monitoring dashboard

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (React + Vite)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Code Editor  â”‚  â”‚ Visualizationâ”‚  â”‚   Pedagogy   â”‚      â”‚
â”‚  â”‚  Component   â”‚  â”‚    Panel     â”‚  â”‚     Panel    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Backend (Node.js + Express)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ AST Parser   â”‚  â”‚  Sentiment   â”‚  â”‚   Pedagogy   â”‚    â”‚
â”‚  â”‚ + Visualizer â”‚  â”‚   Analyzer   â”‚  â”‚    Engine    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                            â”‚                                â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚                    â”‚  Ollama Client â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚ HTTP (localhost:11434)
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  Ollama Service  â”‚
                      â”‚ (Llama-3-8B/Gemma)â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸš€ Quick Start

### Prerequisites

- Node.js 18+ and npm
- Ollama installed ([installation guide](https://ollama.ai/download))
- 8GB+ RAM (16GB recommended)
- 10GB disk space

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/lumina.git
cd lumina
```

2. **Install dependencies**
```bash
npm install
```

3. **Install and start Ollama**
```bash
# Install Ollama (if not already installed)
# Visit: https://ollama.ai/download

# Pull the Llama-3-8B model
ollama pull llama3

# Verify Ollama is running
curl http://localhost:11434/api/tags
```

4. **Start the development servers**

```bash
# Terminal 1: Start backend
cd backend
npm run dev

# Terminal 2: Start frontend
cd frontend
npm run dev
```

5. **Open your browser**
```
http://localhost:5173
```

## ðŸ“– Usage

### Basic Workflow

1. **Write code** in the editor (left panel)
2. **See visualization** update in real-time (top right)
3. **Ask questions** in the chat panel (bottom right)
4. **Watch frustration meter** adapt teaching approach

### Example Interaction

**User writes:**
```javascript
if (x = 5) {
  console.log("x is 5");
}
```

**Lumina (Low Frustration):**
> "I notice you're using a single = in your if statement. What's the difference between = and === in JavaScript?"

**User:** "I don't know, this is confusing"

**Lumina (Medium Frustration - detected keyword "confusing"):**
> "Let's break this down: = assigns a value, while === compares values. In your code, what do you think happens when you write x = 5 inside the if condition?"

**User:** "I've tried everything, just tell me!"

**Lumina (High Frustration - detected "tried everything"):**
> "I can see this is tricky! Here's what's happening:
> - x = 5 assigns 5 to x and returns 5 (truthy)
> - x === 5 compares x to 5 and returns true/false
> 
> Your if statement will always execute because x = 5 returns 5, which is truthy. Try changing = to === to compare instead of assign."

## ðŸ› ï¸ Technical Details

### AST Parsing with Caching
- Uses @babel/parser with visitor pattern
- SHA-256 hashing for cache keys
- LRU cache (50 entries, >80% hit rate target)
- Error recovery for partial AST generation

### Sentiment Detection Algorithm
```typescript
frustrationScore = 
  (1 - baseSentiment) * 25 +     // Base sentiment (-1..1 â†’ 0..50)
  keywordScore +                  // Weighted keywords (0-40)
  repetitionPenalty +             // Levenshtein distance (0-15)
  lengthPenalty +                 // Message length (0-10)
  intensityPenalty                // Caps/exclamations (0-15)
```

**Thresholds:**
- 0-30%: Low frustration â†’ Socratic questions
- 31-70%: Medium frustration â†’ Hints + questions
- 71-100%: High frustration â†’ Direct explanations

### Prompt Engineering
- 3-tier teaching modes (Socratic Explorer, Supportive Guide, Direct Mentor)
- Context window: 12,000 tokens (10 conversation turns + code)
- Response limit: 300 tokens (~200 words)
- Temperature: 0.9 (calm) â†’ 0.7 (frustrated)

## ðŸ“Š Performance

| Metric | Target | Typical |
|--------|--------|---------|
| AST Parsing | <500ms | 150-300ms |
| Mermaid Generation | <200ms | 50-100ms |
| LLM First Token | <1s | 800ms-1.2s |
| LLM Streaming | >30 tok/s | 40-60 tok/s |
| UI Responsiveness | <16ms | 8-12ms |

**Hardware Requirements:**
- Minimum: 8GB RAM, 4-core CPU (4-bit Gemma)
- Recommended: 16GB RAM, 6-core CPU or GPU (8-bit Llama-3)
- Optimal: 32GB RAM, RTX 3060 or M1 Pro (FP16 Llama-3)

## ðŸ”’ Privacy & Security

- âœ… 100% local processing (no cloud calls)
- âœ… Code never leaves your machine
- âœ… No telemetry or analytics
- âœ… No user authentication required
- âœ… Works completely offline after setup
- âœ… Input validation and XSS prevention
- âœ… Prompt injection protection

## ðŸ§ª Testing

```bash
# Run backend tests
cd backend
npm test

# Run frontend tests
cd frontend
npm test

# Run E2E tests
npm run test:e2e
```

## ðŸ“ Project Structure

```
lumina/
â”œâ”€â”€ frontend/           # React + Vite frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/ # UI components
â”‚   â”‚   â”œâ”€â”€ App.tsx     # Main app
â”‚   â”‚   â””â”€â”€ main.tsx    # Entry point
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ backend/            # Node.js + Express backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ services/   # Core services
â”‚   â”‚   â”‚   â”œâ”€â”€ ast-parser.ts      # AST parsing + caching
â”‚   â”‚   â”‚   â”œâ”€â”€ visualizer.ts      # Mermaid generation
â”‚   â”‚   â”‚   â”œâ”€â”€ sentiment.ts       # Frustration detection
â”‚   â”‚   â”‚   â””â”€â”€ pedagogy.ts        # LLM integration
â”‚   â”‚   â”œâ”€â”€ routes/     # API routes
â”‚   â”‚   â””â”€â”€ index.ts    # Server entry
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ shared/             # Shared TypeScript types
â”‚   â””â”€â”€ src/types.ts
â”œâ”€â”€ .kiro/specs/        # Specification documents
â”‚   â””â”€â”€ lumina/
â”‚       â”œâ”€â”€ requirements.md
â”‚       â”œâ”€â”€ design.md
â”‚       â””â”€â”€ IMPROVEMENTS_SUMMARY.md
â””â”€â”€ README.md
```

## ðŸ¤ Contributing

Contributions welcome! Please read [CONTRIBUTING.md](CONTRIBUTING.md) first.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ðŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ™ Acknowledgments

- [Ollama](https://ollama.ai/) for local LLM runtime
- [Babel](https://babeljs.io/) for AST parsing
- [Mermaid](https://mermaid.js.org/) for diagram generation
- [React Flow](https://reactflow.dev/) for interactive visualizations
- [Sentiment.js](https://github.com/thisandagain/sentiment) for sentiment analysis

## ðŸ“§ Contact

- GitHub: [@Ritesh-Root](https://github.com/Ritesh-Root)
- Email: riteshmahatowork@gmail.com

---

**Built with â¤ï¸ for beginner developers who deserve patient, adaptive guidance**
